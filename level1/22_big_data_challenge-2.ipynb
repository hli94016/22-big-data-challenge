{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22-big-data-challenge-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6YJvSJePKlh",
        "outputId": "cdedc244-eb1f-4670-c20a-f1f318de73a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.162.110)] [\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Connected to cloud.\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 242 kB] [3 InRelease 14.2 kB/88.7 kB 16%] [2 InRelease 14.\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [907 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,494 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,725 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [941 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,165 kB]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [953 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,947 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [996 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 15.7 MB in 8s (2,021 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "spark_version = 'spark-3.2.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!rm -rf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use MySQL instead of postgre\n",
        "!rm -f mysql-connector-java-8.0.20.tar.gz\n",
        "!wget https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-8.0.20.tar.gz\n",
        "!tar -zxf mysql-connector-java-8.0.20.tar.gz mysql-connector-java-8.0.20/mysql-connector-java-8.0.20.jar\n",
        "!mv mysql-connector-java-8.0.20/mysql-connector-java-8.0.20.jar .\n",
        "!rmdir mysql-connector-java-8.0.20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHEbN438PPwi",
        "outputId": "851f7bfd-dad4-4a2a-e927-112f623b9057"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-20 00:41:24--  https://downloads.mysql.com/archives/get/p/3/file/mysql-connector-java-8.0.20.tar.gz\n",
            "Resolving downloads.mysql.com (downloads.mysql.com)... 137.254.60.14\n",
            "Connecting to downloads.mysql.com (downloads.mysql.com)|137.254.60.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn.mysql.com/archives/mysql-connector-java-8.0/mysql-connector-java-8.0.20.tar.gz [following]\n",
            "--2022-04-20 00:41:24--  https://cdn.mysql.com/archives/mysql-connector-java-8.0/mysql-connector-java-8.0.20.tar.gz\n",
            "Resolving cdn.mysql.com (cdn.mysql.com)... 23.49.97.31\n",
            "Connecting to cdn.mysql.com (cdn.mysql.com)|23.49.97.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3930793 (3.7M) [application/x-tar-gz]\n",
            "Saving to: ‘mysql-connector-java-8.0.20.tar.gz’\n",
            "\n",
            "mysql-connector-jav 100%[===================>]   3.75M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-04-20 00:41:24 (42.7 MB/s) - ‘mysql-connector-java-8.0.20.tar.gz’ saved [3930793/3930793]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"mysql-connector-java-8.0.20.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "p8CP6ViYPRkK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "# Load in sample_us.tsv from S3 into a DataFrame\n",
        "# url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\"\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Luggage_v1_00.tsv.gz\"\n",
        "file_name = os.path.basename(url)\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read.option('header', 'true').csv(SparkFiles.get(file_name), inferSchema=True, sep='\\t', timestampFormat=\"yyyy-mm-dd\")\n",
        "# Drop duplicated rows if there is any\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Drop rows with null values if there is any\n",
        "df = df.dropna()\n",
        "\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-6LXP2YPTUa",
        "outputId": "6c559948-f9ee-46c1-ff69-5c0346af042b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|         US|   42610491| R5MPHGZNMQRNJ|B00EAKKOKW|     393337306|Samsonite Fiero H...|         Luggage|          5|            0|          0|   N|                Y|          Five Stars|Nothing to compla...|2015-01-31 00:08:00|\n",
            "|         US|   22778458|R2SCIZ2KIIW7G2|B00VWKS05Y|     197290186|World Traveler 21...|         Luggage|          5|            0|          0|   N|                Y|          Five Stars|             love it|2015-01-31 00:08:00|\n",
            "|         US|    8405243|R2Z98HWZHMV78N|B00UQOUBV8|     960742333|Kenox Canvas Scho...|         Luggage|          5|            0|          0|   N|                Y|I like how the ba...|I just received t...|2015-01-30 00:08:00|\n",
            "|         US|   27718120|R1LSO9GG4P33VV|B00BYFC4Z4|     506088001|Eagle Creek Pack-...|         Luggage|          5|            0|          0|   N|                Y|              Great!|Great product ver...|2015-01-30 00:08:00|\n",
            "|         US|   14600611| RS8HVEPCCM1V1|B002YM70QO|     479181625|Eagle Creek Trave...|         Luggage|          4|            0|          0|   N|                Y|          Four Stars|               Spacy|2015-01-30 00:08:00|\n",
            "|         US|   44080043|R2CRLDSELLXESD|B00JM2DLLC|      11240118|EcoCity Multipurp...|         Luggage|          1|            1|          3|   N|                N|It looks cool and...|It looks cool and...|2015-01-30 00:08:00|\n",
            "|         US|   43765856|R3ORL5J14E2IV7|B00CPSWD8C|     677901073|Travelon Anti-The...|         Luggage|          5|           27|         28|   N|                Y|Great for travel ...|Got this bag afte...|2015-01-30 00:08:00|\n",
            "|         US|   36190140|R2DC5GLVE7KPWC|B000P8JBPC|      48200029|Olympia Deluxe Ga...|         Luggage|          5|            0|          0|   N|                N|Has to be one of ...|Has to be one of ...|2015-01-29 00:08:00|\n",
            "|         US|   34140095|R1D7LO4KL2XYNS|B013EAIRPM|     677597111|Ungrol Water Resi...|         Luggage|          3|            1|          1|   N|                Y|The Good and the Bad|I both love and a...|2015-01-29 00:08:00|\n",
            "|         US|    9090247|R3RE7EL02TIN1X|B00MPSGZT0|     668538183|3D Animal Rabbit ...|         Luggage|          5|            0|          0|   N|                Y|Great for toddler...|Great for toddler...|2015-01-28 00:08:00|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_cFydqkPYq4",
        "outputId": "da323ddf-ceb4-4015-b06a-1b8e18fb4d55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "348613"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframes for tables: review_id_table, products, vine_table\n",
        "# review_id_table\n",
        "review_id_df = df[['review_id', 'customer_id', 'product_id', 'product_parent', 'review_date']]\n",
        "review_id_df = review_id_df.drop_duplicates()\n",
        "review_id_df = review_id_df.dropna()\n",
        "\n",
        "# products table\n",
        "products_df = df[['product_id', 'product_title']]\n",
        "products_df = products_df.drop_duplicates()\n",
        "products_df = products_df.dropna()\n",
        "\n",
        "# customers table\n",
        "customers_df = df.groupBy('customer_id').count()\n",
        "customers_df = customers_df.withColumnRenamed(\"count\", \"customer_count\")\n",
        "customers_df = customers_df.drop_duplicates()\n",
        "customers_df = customers_df.dropna()\n",
        "\n",
        "\n",
        "# vine_table\n",
        "vine_df = df[['review_id', 'star_rating', 'helpful_votes', 'total_votes', 'vine']]\n",
        "vine_df = vine_df.drop_duplicates()\n",
        "vine_df = vine_df.dropna()"
      ],
      "metadata": {
        "id": "1stbNJKjPZdJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration for RDS instance\n",
        "mode=\"append\"\n",
        "jdbc_url = \"jdbc:mysql://rds-big-data.cszz1vg6fdhl.us-west-1.rds.amazonaws.com:3306/big_data?useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true\"\n",
        "config = {\"user\":\"admin\",\n",
        "          \"password\": \"password\",\n",
        "          \"driver\":\"com.mysql.jdbc.Driver\"}"
      ],
      "metadata": {
        "id": "1sauzph6PbCt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write vine DataFrame to vine table\n",
        "vine_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "pqDpR6gTPggf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write vine DataFrame to vine table\n",
        "review_id_df.write.jdbc(url=jdbc_url, table='review_id_table', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "2krmLFD5Pi-T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write products DataFrame to products table\n",
        "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "QMb-JAcvPkhi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write customers DataFrame to customers table\n",
        "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ],
      "metadata": {
        "id": "Eh46FO1mPmDd"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}